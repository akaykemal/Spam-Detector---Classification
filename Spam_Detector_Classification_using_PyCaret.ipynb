{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29Fe17j44bm9"
   },
   "source": [
    "# Spam Detector - Classification with PyCaret\n",
    "## Making a Spam Detector\n",
    "This version was made after the Kaggle Version without using PyCaret and was made in colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uAcE0SS13-oi"
   },
   "outputs": [],
   "source": [
    "#pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xd8RQvhO4Xcj"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tR6P0oBV4juL"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "train=pd.read_csv('/content/train.csv')\n",
    "labels=pd.read_csv(\"/content/train_labels.csv\")\n",
    "df=pd.concat([train,labels], axis=1) # combine train and label\n",
    "df.rename(columns={'0': 'label'}, inplace=True) # rename column from '0' to 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "i4uxIp4X4449",
    "outputId": "3b45e5d4-6f9d-4fba-ff85-a2301ccfb4e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8de7174b-a834-42d3-be56-f315641c3fc2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.097094</th>\n",
       "      <th>1.1133</th>\n",
       "      <th>45.038</th>\n",
       "      <th>0.88184</th>\n",
       "      <th>0.087009</th>\n",
       "      <th>1.041</th>\n",
       "      <th>1.5486</th>\n",
       "      <th>3.498</th>\n",
       "      <th>1.8578</th>\n",
       "      <th>0.0096729</th>\n",
       "      <th>4.5162</th>\n",
       "      <th>2.4716</th>\n",
       "      <th>0.07963</th>\n",
       "      <th>4.0896</th>\n",
       "      <th>1.6902</th>\n",
       "      <th>0.91547</th>\n",
       "      <th>0.091189</th>\n",
       "      <th>1.4153</th>\n",
       "      <th>3.1192</th>\n",
       "      <th>0.0060186</th>\n",
       "      <th>0.014375</th>\n",
       "      <th>0.037306</th>\n",
       "      <th>0.61815</th>\n",
       "      <th>0.055585</th>\n",
       "      <th>0.01074</th>\n",
       "      <th>3.0279</th>\n",
       "      <th>1.8636</th>\n",
       "      <th>0.014393</th>\n",
       "      <th>0.21286</th>\n",
       "      <th>2.5653</th>\n",
       "      <th>NaN</th>\n",
       "      <th>0.028234</th>\n",
       "      <th>0.040381</th>\n",
       "      <th>0.065676</th>\n",
       "      <th>0.79874</th>\n",
       "      <th>6.0681</th>\n",
       "      <th>1.3486</th>\n",
       "      <th>0.78914</th>\n",
       "      <th>0.48925</th>\n",
       "      <th>0.044965</th>\n",
       "      <th>3.6954</th>\n",
       "      <th>1.6518</th>\n",
       "      <th>NaN.1</th>\n",
       "      <th>2.0031</th>\n",
       "      <th>1.6097</th>\n",
       "      <th>4.2557</th>\n",
       "      <th>0.016952</th>\n",
       "      <th>1.6888</th>\n",
       "      <th>0.070763</th>\n",
       "      <th>0.028963</th>\n",
       "      <th>3.469</th>\n",
       "      <th>0.04013</th>\n",
       "      <th>0.651</th>\n",
       "      <th>0.076915</th>\n",
       "      <th>0.82981</th>\n",
       "      <th>2.6242</th>\n",
       "      <th>0.0077223</th>\n",
       "      <th>1.9591</th>\n",
       "      <th>0.091773</th>\n",
       "      <th>0.0014508</th>\n",
       "      <th>0.062135</th>\n",
       "      <th>0.097433</th>\n",
       "      <th>0.081459</th>\n",
       "      <th>0.089605</th>\n",
       "      <th>0.019517</th>\n",
       "      <th>0.39503</th>\n",
       "      <th>2.201</th>\n",
       "      <th>3.6572</th>\n",
       "      <th>0.022237</th>\n",
       "      <th>0.042535</th>\n",
       "      <th>4.525</th>\n",
       "      <th>0.16949</th>\n",
       "      <th>0.67231</th>\n",
       "      <th>0.052349</th>\n",
       "      <th>4.6379</th>\n",
       "      <th>0.012962</th>\n",
       "      <th>0.019132</th>\n",
       "      <th>4.5504</th>\n",
       "      <th>0.005637</th>\n",
       "      <th>0.26957</th>\n",
       "      <th>3.5743</th>\n",
       "      <th>0.040547</th>\n",
       "      <th>3.4724</th>\n",
       "      <th>0.0049949</th>\n",
       "      <th>0.023048</th>\n",
       "      <th>1.916</th>\n",
       "      <th>0.77773</th>\n",
       "      <th>0.032171</th>\n",
       "      <th>NaN.2</th>\n",
       "      <th>0.041627</th>\n",
       "      <th>0.076209</th>\n",
       "      <th>3.6654</th>\n",
       "      <th>0.061607</th>\n",
       "      <th>0.0031605</th>\n",
       "      <th>0.036038</th>\n",
       "      <th>0.0845</th>\n",
       "      <th>2.4517</th>\n",
       "      <th>3.3373</th>\n",
       "      <th>0.065201</th>\n",
       "      <th>0.091158</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050086</td>\n",
       "      <td>0.11158</td>\n",
       "      <td>94.0800</td>\n",
       "      <td>1.76500</td>\n",
       "      <td>0.089417</td>\n",
       "      <td>4.80470</td>\n",
       "      <td>0.26742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.56473</td>\n",
       "      <td>0.035123</td>\n",
       "      <td>1.48270</td>\n",
       "      <td>2.5929</td>\n",
       "      <td>0.223980</td>\n",
       "      <td>3.9993</td>\n",
       "      <td>3.4247</td>\n",
       "      <td>1.79450</td>\n",
       "      <td>0.070337</td>\n",
       "      <td>0.7135</td>\n",
       "      <td>1.1426</td>\n",
       "      <td>0.018661</td>\n",
       "      <td>0.065120</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060869</td>\n",
       "      <td>0.083399</td>\n",
       "      <td>2.1228</td>\n",
       "      <td>0.73517</td>\n",
       "      <td>0.096963</td>\n",
       "      <td>0.011055</td>\n",
       "      <td>3.9510</td>\n",
       "      <td>0.091110</td>\n",
       "      <td>0.018081</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>0.017668</td>\n",
       "      <td>0.91469</td>\n",
       "      <td>41.0140</td>\n",
       "      <td>3.707000</td>\n",
       "      <td>2.0693</td>\n",
       "      <td>4.95710</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>4.3729</td>\n",
       "      <td>3.23560</td>\n",
       "      <td>0.092688</td>\n",
       "      <td>0.22587</td>\n",
       "      <td>6.3327</td>\n",
       "      <td>2.56210</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>4.17120</td>\n",
       "      <td>0.043128</td>\n",
       "      <td>1.895900</td>\n",
       "      <td>0.19076</td>\n",
       "      <td>0.049980</td>\n",
       "      <td>0.968310</td>\n",
       "      <td>0.095265</td>\n",
       "      <td>4.9342</td>\n",
       "      <td>3.6403</td>\n",
       "      <td>0.085841</td>\n",
       "      <td>2.5845</td>\n",
       "      <td>0.038742</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.052713</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>0.094237</td>\n",
       "      <td>0.036511</td>\n",
       "      <td>0.071179</td>\n",
       "      <td>0.23586</td>\n",
       "      <td>4.07320</td>\n",
       "      <td>1.24440</td>\n",
       "      <td>0.094579</td>\n",
       "      <td>0.931980</td>\n",
       "      <td>2.35650</td>\n",
       "      <td>0.82129</td>\n",
       "      <td>0.049131</td>\n",
       "      <td>0.027010</td>\n",
       "      <td>1.8648</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.048432</td>\n",
       "      <td>0.73120</td>\n",
       "      <td>0.099694</td>\n",
       "      <td>0.168960</td>\n",
       "      <td>1.63890</td>\n",
       "      <td>2.739500</td>\n",
       "      <td>0.55716</td>\n",
       "      <td>0.070742</td>\n",
       "      <td>0.022589</td>\n",
       "      <td>1.6064</td>\n",
       "      <td>3.03450</td>\n",
       "      <td>0.063698</td>\n",
       "      <td>0.951680</td>\n",
       "      <td>0.065822</td>\n",
       "      <td>0.054712</td>\n",
       "      <td>4.16870</td>\n",
       "      <td>0.075432</td>\n",
       "      <td>0.010869</td>\n",
       "      <td>0.063972</td>\n",
       "      <td>0.079892</td>\n",
       "      <td>1.9795</td>\n",
       "      <td>3.5064</td>\n",
       "      <td>0.072132</td>\n",
       "      <td>0.091950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088447</td>\n",
       "      <td>2.36340</td>\n",
       "      <td>5.0580</td>\n",
       "      <td>0.14436</td>\n",
       "      <td>0.064547</td>\n",
       "      <td>2.44400</td>\n",
       "      <td>4.25450</td>\n",
       "      <td>0.36506</td>\n",
       "      <td>1.86090</td>\n",
       "      <td>0.009759</td>\n",
       "      <td>3.50750</td>\n",
       "      <td>3.6126</td>\n",
       "      <td>0.019720</td>\n",
       "      <td>2.2723</td>\n",
       "      <td>1.1937</td>\n",
       "      <td>1.03690</td>\n",
       "      <td>0.086313</td>\n",
       "      <td>1.5003</td>\n",
       "      <td>2.3868</td>\n",
       "      <td>0.052785</td>\n",
       "      <td>0.087950</td>\n",
       "      <td>0.067695</td>\n",
       "      <td>1.46600</td>\n",
       "      <td>0.024131</td>\n",
       "      <td>0.035304</td>\n",
       "      <td>1.4450</td>\n",
       "      <td>3.83900</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.092129</td>\n",
       "      <td>4.7438</td>\n",
       "      <td>0.033202</td>\n",
       "      <td>0.083371</td>\n",
       "      <td>0.014163</td>\n",
       "      <td>0.055091</td>\n",
       "      <td>5.06020</td>\n",
       "      <td>1.0771</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>4.0361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019126</td>\n",
       "      <td>1.9285</td>\n",
       "      <td>0.77643</td>\n",
       "      <td>0.018482</td>\n",
       "      <td>4.57630</td>\n",
       "      <td>1.0067</td>\n",
       "      <td>1.57450</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.34146</td>\n",
       "      <td>0.048967</td>\n",
       "      <td>0.019560</td>\n",
       "      <td>2.01550</td>\n",
       "      <td>0.072080</td>\n",
       "      <td>0.087619</td>\n",
       "      <td>0.094343</td>\n",
       "      <td>3.9453</td>\n",
       "      <td>0.5248</td>\n",
       "      <td>0.082408</td>\n",
       "      <td>1.3841</td>\n",
       "      <td>0.032529</td>\n",
       "      <td>0.024050</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.067660</td>\n",
       "      <td>0.023938</td>\n",
       "      <td>0.090783</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>2.95580</td>\n",
       "      <td>3.86110</td>\n",
       "      <td>3.76860</td>\n",
       "      <td>0.071469</td>\n",
       "      <td>0.089305</td>\n",
       "      <td>1.73020</td>\n",
       "      <td>3.76830</td>\n",
       "      <td>0.047478</td>\n",
       "      <td>0.090466</td>\n",
       "      <td>5.0165</td>\n",
       "      <td>0.088609</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>1.04530</td>\n",
       "      <td>0.032310</td>\n",
       "      <td>0.090294</td>\n",
       "      <td>5.02590</td>\n",
       "      <td>0.081161</td>\n",
       "      <td>1.05090</td>\n",
       "      <td>0.015816</td>\n",
       "      <td>20.088000</td>\n",
       "      <td>1.0700</td>\n",
       "      <td>4.34680</td>\n",
       "      <td>0.061113</td>\n",
       "      <td>0.073222</td>\n",
       "      <td>0.098675</td>\n",
       "      <td>0.017203</td>\n",
       "      <td>4.56130</td>\n",
       "      <td>0.046505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084066</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>3.3087</td>\n",
       "      <td>2.9969</td>\n",
       "      <td>0.064328</td>\n",
       "      <td>0.036793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.772540</td>\n",
       "      <td>0.59469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97515</td>\n",
       "      <td>0.015987</td>\n",
       "      <td>0.52884</td>\n",
       "      <td>1.48840</td>\n",
       "      <td>3.96100</td>\n",
       "      <td>4.80630</td>\n",
       "      <td>0.048617</td>\n",
       "      <td>2.72120</td>\n",
       "      <td>2.5029</td>\n",
       "      <td>0.023355</td>\n",
       "      <td>4.5088</td>\n",
       "      <td>3.1327</td>\n",
       "      <td>3.86270</td>\n",
       "      <td>0.090923</td>\n",
       "      <td>4.3838</td>\n",
       "      <td>2.1928</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>0.099073</td>\n",
       "      <td>0.019689</td>\n",
       "      <td>2.21980</td>\n",
       "      <td>0.042799</td>\n",
       "      <td>0.037704</td>\n",
       "      <td>4.1482</td>\n",
       "      <td>4.07180</td>\n",
       "      <td>0.017883</td>\n",
       "      <td>0.092244</td>\n",
       "      <td>3.6523</td>\n",
       "      <td>0.010751</td>\n",
       "      <td>0.055596</td>\n",
       "      <td>0.015418</td>\n",
       "      <td>0.093861</td>\n",
       "      <td>0.94272</td>\n",
       "      <td>1.0224</td>\n",
       "      <td>7.564100</td>\n",
       "      <td>2.6595</td>\n",
       "      <td>1.47560</td>\n",
       "      <td>0.772090</td>\n",
       "      <td>2.9316</td>\n",
       "      <td>1.82140</td>\n",
       "      <td>0.036775</td>\n",
       "      <td>3.85380</td>\n",
       "      <td>1.0653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>4.51470</td>\n",
       "      <td>0.088371</td>\n",
       "      <td>0.098904</td>\n",
       "      <td>4.13170</td>\n",
       "      <td>0.020435</td>\n",
       "      <td>0.364220</td>\n",
       "      <td>0.049476</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>3.1788</td>\n",
       "      <td>0.040688</td>\n",
       "      <td>2.2262</td>\n",
       "      <td>0.050689</td>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.087453</td>\n",
       "      <td>0.022281</td>\n",
       "      <td>0.041949</td>\n",
       "      <td>0.022086</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>2.94100</td>\n",
       "      <td>0.98445</td>\n",
       "      <td>0.91658</td>\n",
       "      <td>0.050185</td>\n",
       "      <td>0.040575</td>\n",
       "      <td>1.52540</td>\n",
       "      <td>1.27960</td>\n",
       "      <td>0.014323</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>0.9157</td>\n",
       "      <td>0.019139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.49430</td>\n",
       "      <td>0.081137</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>0.13016</td>\n",
       "      <td>1.063700</td>\n",
       "      <td>4.94410</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.041079</td>\n",
       "      <td>1.5943</td>\n",
       "      <td>4.62410</td>\n",
       "      <td>0.407080</td>\n",
       "      <td>0.051634</td>\n",
       "      <td>0.057662</td>\n",
       "      <td>0.022891</td>\n",
       "      <td>0.12832</td>\n",
       "      <td>0.065028</td>\n",
       "      <td>0.036862</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>0.020709</td>\n",
       "      <td>2.5237</td>\n",
       "      <td>2.1711</td>\n",
       "      <td>0.080865</td>\n",
       "      <td>0.081553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.382410</td>\n",
       "      <td>4.81090</td>\n",
       "      <td>1955.1000</td>\n",
       "      <td>0.46050</td>\n",
       "      <td>0.024453</td>\n",
       "      <td>2.02980</td>\n",
       "      <td>3.74030</td>\n",
       "      <td>4.22810</td>\n",
       "      <td>2.42920</td>\n",
       "      <td>0.156830</td>\n",
       "      <td>4.67990</td>\n",
       "      <td>1.2061</td>\n",
       "      <td>0.160480</td>\n",
       "      <td>4.3383</td>\n",
       "      <td>1.7294</td>\n",
       "      <td>4.15550</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>4.9250</td>\n",
       "      <td>4.3986</td>\n",
       "      <td>0.070821</td>\n",
       "      <td>0.034121</td>\n",
       "      <td>0.087522</td>\n",
       "      <td>0.17924</td>\n",
       "      <td>0.097594</td>\n",
       "      <td>0.310430</td>\n",
       "      <td>5.0021</td>\n",
       "      <td>0.79369</td>\n",
       "      <td>0.100470</td>\n",
       "      <td>0.134130</td>\n",
       "      <td>3.0778</td>\n",
       "      <td>0.053728</td>\n",
       "      <td>0.066446</td>\n",
       "      <td>0.391440</td>\n",
       "      <td>0.028428</td>\n",
       "      <td>3.18730</td>\n",
       "      <td>181.0600</td>\n",
       "      <td>2.794400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.34760</td>\n",
       "      <td>0.646900</td>\n",
       "      <td>4.6828</td>\n",
       "      <td>3.89630</td>\n",
       "      <td>0.072960</td>\n",
       "      <td>0.61090</td>\n",
       "      <td>3.3776</td>\n",
       "      <td>0.29307</td>\n",
       "      <td>0.083117</td>\n",
       "      <td>4.00290</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>0.397220</td>\n",
       "      <td>4.28580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066497</td>\n",
       "      <td>0.754690</td>\n",
       "      <td>2.8442</td>\n",
       "      <td>3.9069</td>\n",
       "      <td>0.066547</td>\n",
       "      <td>3.6738</td>\n",
       "      <td>0.093712</td>\n",
       "      <td>0.026305</td>\n",
       "      <td>0.186150</td>\n",
       "      <td>0.049486</td>\n",
       "      <td>0.042992</td>\n",
       "      <td>0.256420</td>\n",
       "      <td>0.294860</td>\n",
       "      <td>1.28700</td>\n",
       "      <td>0.80866</td>\n",
       "      <td>0.42315</td>\n",
       "      <td>0.094649</td>\n",
       "      <td>0.217580</td>\n",
       "      <td>2.71120</td>\n",
       "      <td>2.14700</td>\n",
       "      <td>0.430170</td>\n",
       "      <td>0.042579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043946</td>\n",
       "      <td>0.067050</td>\n",
       "      <td>4.97960</td>\n",
       "      <td>0.061703</td>\n",
       "      <td>0.478570</td>\n",
       "      <td>1.70650</td>\n",
       "      <td>1.437800</td>\n",
       "      <td>3.82900</td>\n",
       "      <td>0.405630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6429</td>\n",
       "      <td>4.75050</td>\n",
       "      <td>0.377560</td>\n",
       "      <td>0.520420</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>0.032051</td>\n",
       "      <td>4.37010</td>\n",
       "      <td>1.001100</td>\n",
       "      <td>0.065750</td>\n",
       "      <td>0.043547</td>\n",
       "      <td>0.629430</td>\n",
       "      <td>4.6262</td>\n",
       "      <td>3.1947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.187180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081316</td>\n",
       "      <td>4.84150</td>\n",
       "      <td>4.0507</td>\n",
       "      <td>2.48320</td>\n",
       "      <td>0.058990</td>\n",
       "      <td>2.37940</td>\n",
       "      <td>1.61270</td>\n",
       "      <td>2.04220</td>\n",
       "      <td>1.65710</td>\n",
       "      <td>0.039377</td>\n",
       "      <td>0.65003</td>\n",
       "      <td>2.4241</td>\n",
       "      <td>0.083921</td>\n",
       "      <td>3.2717</td>\n",
       "      <td>1.2791</td>\n",
       "      <td>0.76711</td>\n",
       "      <td>0.077046</td>\n",
       "      <td>4.0043</td>\n",
       "      <td>4.4889</td>\n",
       "      <td>0.017876</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.051383</td>\n",
       "      <td>0.10942</td>\n",
       "      <td>0.033228</td>\n",
       "      <td>0.073198</td>\n",
       "      <td>3.8304</td>\n",
       "      <td>0.97449</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.064099</td>\n",
       "      <td>4.5370</td>\n",
       "      <td>0.031019</td>\n",
       "      <td>0.054224</td>\n",
       "      <td>0.059163</td>\n",
       "      <td>0.008945</td>\n",
       "      <td>2.34420</td>\n",
       "      <td>1.0860</td>\n",
       "      <td>0.039963</td>\n",
       "      <td>1.4863</td>\n",
       "      <td>0.71081</td>\n",
       "      <td>0.097040</td>\n",
       "      <td>3.4237</td>\n",
       "      <td>1.37260</td>\n",
       "      <td>0.079467</td>\n",
       "      <td>2.17210</td>\n",
       "      <td>1.0799</td>\n",
       "      <td>1.64600</td>\n",
       "      <td>0.031722</td>\n",
       "      <td>4.07620</td>\n",
       "      <td>0.066266</td>\n",
       "      <td>0.022077</td>\n",
       "      <td>0.75201</td>\n",
       "      <td>0.037699</td>\n",
       "      <td>0.086819</td>\n",
       "      <td>0.089568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4755</td>\n",
       "      <td>0.098918</td>\n",
       "      <td>2.8581</td>\n",
       "      <td>0.068503</td>\n",
       "      <td>0.038058</td>\n",
       "      <td>0.058369</td>\n",
       "      <td>0.053831</td>\n",
       "      <td>0.042403</td>\n",
       "      <td>0.037323</td>\n",
       "      <td>0.059348</td>\n",
       "      <td>3.76920</td>\n",
       "      <td>2.36730</td>\n",
       "      <td>2.47470</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.013585</td>\n",
       "      <td>0.75453</td>\n",
       "      <td>1.30130</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>3.5942</td>\n",
       "      <td>0.023379</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.96592</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.092793</td>\n",
       "      <td>2.69380</td>\n",
       "      <td>0.096934</td>\n",
       "      <td>0.26088</td>\n",
       "      <td>0.063095</td>\n",
       "      <td>0.024237</td>\n",
       "      <td>1.8117</td>\n",
       "      <td>0.72178</td>\n",
       "      <td>0.041385</td>\n",
       "      <td>0.033927</td>\n",
       "      <td>0.091891</td>\n",
       "      <td>0.018918</td>\n",
       "      <td>2.68040</td>\n",
       "      <td>0.076524</td>\n",
       "      <td>0.082756</td>\n",
       "      <td>0.041953</td>\n",
       "      <td>0.018092</td>\n",
       "      <td>3.3041</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.050172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8de7174b-a834-42d3-be56-f315641c3fc2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8de7174b-a834-42d3-be56-f315641c3fc2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8de7174b-a834-42d3-be56-f315641c3fc2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   0.097094   1.1133     45.038  0.88184  0.087009    1.041   1.5486    3.498  \\\n",
       "0  0.050086  0.11158    94.0800  1.76500  0.089417  4.80470  0.26742      NaN   \n",
       "1  0.088447  2.36340     5.0580  0.14436  0.064547  2.44400  4.25450  0.36506   \n",
       "2  0.772540  0.59469        NaN  0.97515  0.015987  0.52884  1.48840  3.96100   \n",
       "3  0.382410  4.81090  1955.1000  0.46050  0.024453  2.02980  3.74030  4.22810   \n",
       "4  0.081316  4.84150     4.0507  2.48320  0.058990  2.37940  1.61270  2.04220   \n",
       "\n",
       "    1.8578  0.0096729   4.5162  2.4716   0.07963  4.0896  1.6902  0.91547  \\\n",
       "0  0.56473   0.035123  1.48270  2.5929  0.223980  3.9993  3.4247  1.79450   \n",
       "1  1.86090   0.009759  3.50750  3.6126  0.019720  2.2723  1.1937  1.03690   \n",
       "2  4.80630   0.048617  2.72120  2.5029  0.023355  4.5088  3.1327  3.86270   \n",
       "3  2.42920   0.156830  4.67990  1.2061  0.160480  4.3383  1.7294  4.15550   \n",
       "4  1.65710   0.039377  0.65003  2.4241  0.083921  3.2717  1.2791  0.76711   \n",
       "\n",
       "   0.091189  1.4153  3.1192  0.0060186  0.014375  0.037306  0.61815  0.055585  \\\n",
       "0  0.070337  0.7135  1.1426   0.018661  0.065120  0.081132      NaN  0.060869   \n",
       "1  0.086313  1.5003  2.3868   0.052785  0.087950  0.067695  1.46600  0.024131   \n",
       "2  0.090923  4.3838  2.1928   0.026211  0.099073  0.019689  2.21980  0.042799   \n",
       "3  0.004260  4.9250  4.3986   0.070821  0.034121  0.087522  0.17924  0.097594   \n",
       "4  0.077046  4.0043  4.4889   0.017876  0.034194  0.051383  0.10942  0.033228   \n",
       "\n",
       "    0.01074  3.0279   1.8636  0.014393   0.21286  2.5653       NaN  0.028234  \\\n",
       "0  0.083399  2.1228  0.73517  0.096963  0.011055  3.9510  0.091110  0.018081   \n",
       "1  0.035304  1.4450  3.83900  0.000325  0.092129  4.7438  0.033202  0.083371   \n",
       "2  0.037704  4.1482  4.07180  0.017883  0.092244  3.6523  0.010751  0.055596   \n",
       "3  0.310430  5.0021  0.79369  0.100470  0.134130  3.0778  0.053728  0.066446   \n",
       "4  0.073198  3.8304  0.97449  0.031858  0.064099  4.5370  0.031019  0.054224   \n",
       "\n",
       "   0.040381  0.065676  0.79874    6.0681    1.3486  0.78914  0.48925  \\\n",
       "0  0.038182  0.017668  0.91469   41.0140  3.707000   2.0693  4.95710   \n",
       "1  0.014163  0.055091  5.06020    1.0771  0.003966   4.0361      NaN   \n",
       "2  0.015418  0.093861  0.94272    1.0224  7.564100   2.6595  1.47560   \n",
       "3  0.391440  0.028428  3.18730  181.0600  2.794400      NaN  1.34760   \n",
       "4  0.059163  0.008945  2.34420    1.0860  0.039963   1.4863  0.71081   \n",
       "\n",
       "   0.044965  3.6954   1.6518     NaN.1   2.0031  1.6097   4.2557  0.016952  \\\n",
       "0  0.016032  4.3729  3.23560  0.092688  0.22587  6.3327  2.56210  0.030500   \n",
       "1  0.019126  1.9285  0.77643  0.018482  4.57630  1.0067  1.57450  0.054700   \n",
       "2  0.772090  2.9316  1.82140  0.036775  3.85380  1.0653      NaN  0.039000   \n",
       "3  0.646900  4.6828  3.89630  0.072960  0.61090  3.3776  0.29307  0.083117   \n",
       "4  0.097040  3.4237  1.37260  0.079467  2.17210  1.0799  1.64600  0.031722   \n",
       "\n",
       "    1.6888  0.070763  0.028963    3.469   0.04013     0.651  0.076915  \\\n",
       "0  4.17120  0.043128  1.895900  0.19076  0.049980  0.968310  0.095265   \n",
       "1  0.34146  0.048967  0.019560  2.01550  0.072080  0.087619  0.094343   \n",
       "2  4.51470  0.088371  0.098904  4.13170  0.020435  0.364220  0.049476   \n",
       "3  4.00290  0.369800  0.397220  4.28580       NaN  0.066497  0.754690   \n",
       "4  4.07620  0.066266  0.022077  0.75201  0.037699  0.086819  0.089568   \n",
       "\n",
       "   0.82981  2.6242  0.0077223  1.9591  0.091773  0.0014508  0.062135  \\\n",
       "0   4.9342  3.6403   0.085841  2.5845  0.038742   0.000319  0.052713   \n",
       "1   3.9453  0.5248   0.082408  1.3841  0.032529   0.024050  0.000991   \n",
       "2   0.4050  3.1788   0.040688  2.2262  0.050689   0.005585  0.087453   \n",
       "3   2.8442  3.9069   0.066547  3.6738  0.093712   0.026305  0.186150   \n",
       "4      NaN  2.4755   0.098918  2.8581  0.068503   0.038058  0.058369   \n",
       "\n",
       "   0.097433  0.081459  0.089605  0.019517  0.39503    2.201   3.6572  \\\n",
       "0  0.019645  0.094237  0.036511  0.071179  0.23586  4.07320  1.24440   \n",
       "1  0.067660  0.023938  0.090783  0.003342  2.95580  3.86110  3.76860   \n",
       "2  0.022281  0.041949  0.022086  0.008299  2.94100  0.98445  0.91658   \n",
       "3  0.049486  0.042992  0.256420  0.294860  1.28700  0.80866  0.42315   \n",
       "4  0.053831  0.042403  0.037323  0.059348  3.76920  2.36730  2.47470   \n",
       "\n",
       "   0.022237  0.042535    4.525  0.16949   0.67231  0.052349  4.6379  0.012962  \\\n",
       "0  0.094579  0.931980  2.35650  0.82129  0.049131  0.027010  1.8648  0.011165   \n",
       "1  0.071469  0.089305  1.73020  3.76830  0.047478  0.090466  5.0165  0.088609   \n",
       "2  0.050185  0.040575  1.52540  1.27960  0.014323  0.004959  0.9157  0.019139   \n",
       "3  0.094649  0.217580  2.71120  2.14700  0.430170  0.042579     NaN  0.043946   \n",
       "4  0.028761  0.013585  0.75453  1.30130  0.002316  0.000595  3.5942  0.023379   \n",
       "\n",
       "   0.019132   4.5504  0.005637   0.26957   3.5743  0.040547   3.4724  \\\n",
       "0  0.048432  0.73120  0.099694  0.168960  1.63890  2.739500  0.55716   \n",
       "1  0.003601  1.04530  0.032310  0.090294  5.02590  0.081161  1.05090   \n",
       "2       NaN  3.49430  0.081137  0.016771  0.13016  1.063700  4.94410   \n",
       "3  0.067050  4.97960  0.061703  0.478570  1.70650  1.437800  3.82900   \n",
       "4  0.003272  0.96592  0.025424  0.092793  2.69380  0.096934  0.26088   \n",
       "\n",
       "   0.0049949   0.023048   1.916  0.77773  0.032171     NaN.2  0.041627  \\\n",
       "0   0.070742   0.022589  1.6064  3.03450  0.063698  0.951680  0.065822   \n",
       "1   0.015816  20.088000  1.0700  4.34680  0.061113  0.073222  0.098675   \n",
       "2   0.377000   0.041079  1.5943  4.62410  0.407080  0.051634  0.057662   \n",
       "3   0.405630        NaN  1.6429  4.75050  0.377560  0.520420  0.038938   \n",
       "4   0.063095   0.024237  1.8117  0.72178  0.041385  0.033927  0.091891   \n",
       "\n",
       "   0.076209   3.6654  0.061607  0.0031605  0.036038    0.0845  2.4517  3.3373  \\\n",
       "0  0.054712  4.16870  0.075432   0.010869  0.063972  0.079892  1.9795  3.5064   \n",
       "1  0.017203  4.56130  0.046505        NaN  0.084066  0.064829  3.3087  2.9969   \n",
       "2  0.022891  0.12832  0.065028   0.036862  0.010010  0.020709  2.5237  2.1711   \n",
       "3  0.032051  4.37010  1.001100   0.065750  0.043547  0.629430  4.6262  3.1947   \n",
       "4  0.018918  2.68040  0.076524   0.082756  0.041953  0.018092  3.3041  0.1922   \n",
       "\n",
       "   0.065201  0.091158  label  \n",
       "0  0.072132  0.091950      1  \n",
       "1  0.064328  0.036793      0  \n",
       "2  0.080865  0.081553      0  \n",
       "3       NaN  0.187180      1  \n",
       "4  0.032600  0.050172      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fb41d15456094cf8b086eac8938af7d5",
      "aac1e7363822434c8c8330d6689f9324",
      "56a54250ee2b45468c1e479d3af220aa",
      "6226060639964853b57c6d65dc8882c5",
      "59b3b564ff124922bb9dc39c5bb4b33a",
      "074394ebaeec48c7a79e22e9ff612494"
     ]
    },
    "id": "S2rmIFcA4xyI",
    "outputId": "9ce40c20-ce5b-411c-830d-a88b9685452c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-91fda42e-8af2-483b-8113-ba22f64b0df1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>session_id</td>\n",
       "      <td>2401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Target</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Target Type</td>\n",
       "      <td>Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Label Encoded</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Original Data</td>\n",
       "      <td>(599, 101)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Missing Values</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Numeric Features</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Categorical Features</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ordinal Features</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High Cardinality Features</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>High Cardinality Method</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Transformed Train Set</td>\n",
       "      <td>(419, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Transformed Test Set</td>\n",
       "      <td>(180, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Shuffle Train-Test</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stratify Train-Test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fold Generator</td>\n",
       "      <td>StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fold Number</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CPU Jobs</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Use GPU</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Log Experiment</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Experiment Name</td>\n",
       "      <td>clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>USI</td>\n",
       "      <td>befe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Imputation Type</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Iterative Imputation Iteration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Numeric Imputer</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Iterative Imputation Numeric Model</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Categorical Imputer</td>\n",
       "      <td>constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Iterative Imputation Categorical Model</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Unknown Categoricals Handling</td>\n",
       "      <td>least_frequent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Normalize</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Normalize Method</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Transformation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Transformation Method</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PCA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PCA Method</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PCA Components</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ignore Low Variance</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Combine Rare Levels</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rare Level Threshold</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Numeric Binning</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Remove Outliers</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Outliers Threshold</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Remove Multicollinearity</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Multicollinearity Threshold</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Remove Perfect Collinearity</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Clustering</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Clustering Iteration</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Polynomial Features</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Polynomial Degree</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Trignometry Features</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Polynomial Threshold</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Group Features</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Feature Selection</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Feature Selection Method</td>\n",
       "      <td>classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Features Selection Threshold</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Feature Interaction</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Feature Ratio</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Interaction Threshold</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Fix Imbalance</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Fix Imbalance Method</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91fda42e-8af2-483b-8113-ba22f64b0df1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-91fda42e-8af2-483b-8113-ba22f64b0df1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-91fda42e-8af2-483b-8113-ba22f64b0df1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                               Description             Value\n",
       "0                               session_id              2401\n",
       "1                                   Target             label\n",
       "2                              Target Type            Binary\n",
       "3                            Label Encoded              None\n",
       "4                            Original Data        (599, 101)\n",
       "5                           Missing Values              True\n",
       "6                         Numeric Features               100\n",
       "7                     Categorical Features                 0\n",
       "8                         Ordinal Features             False\n",
       "9                High Cardinality Features             False\n",
       "10                 High Cardinality Method              None\n",
       "11                   Transformed Train Set        (419, 100)\n",
       "12                    Transformed Test Set        (180, 100)\n",
       "13                      Shuffle Train-Test              True\n",
       "14                     Stratify Train-Test             False\n",
       "15                          Fold Generator   StratifiedKFold\n",
       "16                             Fold Number                10\n",
       "17                                CPU Jobs                -1\n",
       "18                                 Use GPU             False\n",
       "19                          Log Experiment             False\n",
       "20                         Experiment Name  clf-default-name\n",
       "21                                     USI              befe\n",
       "22                         Imputation Type            simple\n",
       "23          Iterative Imputation Iteration              None\n",
       "24                         Numeric Imputer              mean\n",
       "25      Iterative Imputation Numeric Model              None\n",
       "26                     Categorical Imputer          constant\n",
       "27  Iterative Imputation Categorical Model              None\n",
       "28           Unknown Categoricals Handling    least_frequent\n",
       "29                               Normalize             False\n",
       "30                        Normalize Method              None\n",
       "31                          Transformation             False\n",
       "32                   Transformation Method              None\n",
       "33                                     PCA             False\n",
       "34                              PCA Method              None\n",
       "35                          PCA Components              None\n",
       "36                     Ignore Low Variance             False\n",
       "37                     Combine Rare Levels             False\n",
       "38                    Rare Level Threshold              None\n",
       "39                         Numeric Binning             False\n",
       "40                         Remove Outliers             False\n",
       "41                      Outliers Threshold              None\n",
       "42                Remove Multicollinearity             False\n",
       "43             Multicollinearity Threshold              None\n",
       "44             Remove Perfect Collinearity              True\n",
       "45                              Clustering             False\n",
       "46                    Clustering Iteration              None\n",
       "47                     Polynomial Features             False\n",
       "48                       Polynomial Degree              None\n",
       "49                    Trignometry Features             False\n",
       "50                    Polynomial Threshold              None\n",
       "51                          Group Features             False\n",
       "52                       Feature Selection             False\n",
       "53                Feature Selection Method           classic\n",
       "54            Features Selection Threshold              None\n",
       "55                     Feature Interaction             False\n",
       "56                           Feature Ratio             False\n",
       "57                   Interaction Threshold              None\n",
       "58                           Fix Imbalance             False\n",
       "59                    Fix Imbalance Method             SMOTE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logs:create_model_container: 0\n",
      "INFO:logs:master_model_container: 0\n",
      "INFO:logs:display_container: 1\n",
      "INFO:logs:Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=[],\n",
      "                                      display_types=True, features_todrop=[],\n",
      "                                      id_columns=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=[], target='label',\n",
      "                                      time_features=[])),\n",
      "                ('imputer',\n",
      "                 Simple_Imputer(categorical_strategy='not_available',\n",
      "                                fill_value_categorical=None,\n",
      "                                fill_value_numerical=None,\n",
      "                                numeric_strate...\n",
      "                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
      "                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
      "                ('cluster_all', 'passthrough'),\n",
      "                ('dummy', Dummify(target='label')),\n",
      "                ('fix_perfect', Remove_100(target='label')),\n",
      "                ('clean_names', Clean_Colum_Names()),\n",
      "                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
      "                ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
      "         verbose=False)\n",
      "INFO:logs:setup() succesfully completed......................................\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     0.097094   1.1133       45.038  0.88184  0.087009    1.041   1.5486  \\\n",
       " 135  0.074281  4.47860     9.099700  0.15208  0.179734  2.55650  2.06890   \n",
       " 350  0.002583  4.13580    51.084999  0.30122  0.081628  2.21820  0.84725   \n",
       " 512  0.067082  4.46350   290.332397  1.23530  0.089795  4.77930  3.38170   \n",
       " 192  0.809040  4.94900    71.044998  1.54530  0.765080  1.02950  3.90200   \n",
       " 27   0.040834  4.39190    19.082001  3.90900  0.031405  1.17960  3.68010   \n",
       " ..        ...      ...          ...      ...       ...      ...      ...   \n",
       " 570  0.066086  3.15590   826.020020  1.21120  0.050190  1.08990  4.61700   \n",
       " 379  0.058969  2.28610    79.084000  3.33980  0.010935  3.39960  1.85280   \n",
       " 162  0.017473  4.53250    65.065002  3.34090  0.020600  4.32710  2.53770   \n",
       " 267  0.044203  0.60286    99.008003  1.75950  0.050305  1.58640  4.76790   \n",
       " 409  0.045725  1.15330  1463.099976  0.99884  0.059217  0.49536  3.33280   \n",
       " \n",
       "        3.498  1.8578  0.0096729  ...  0.076209   3.6654  0.061607  0.0031605  \\\n",
       " 135  4.33640  1.3526   0.095312  ...  0.014924  2.72280  0.083425   0.071522   \n",
       " 350  3.16850  3.1680   0.005478  ...  0.052129  0.34151  0.003804   0.067689   \n",
       " 512  3.84310  2.2026   0.028238  ...  0.032006  2.33270  0.075470   0.020081   \n",
       " 192  0.92241  2.7170   0.073644  ...  0.005704  2.20000  0.077198   0.048482   \n",
       " 27   4.27760  1.0407   0.087270  ...  0.057945  0.64577  0.009417   0.053599   \n",
       " ..       ...     ...        ...  ...       ...      ...       ...        ...   \n",
       " 570  2.65490  2.1883   0.046694  ...  0.050400  2.57820  0.045104   0.039356   \n",
       " 379  4.86760  2.2228   0.087276  ...  0.033458  1.31050  0.021490   0.009631   \n",
       " 162  2.41710  4.6191   0.006833  ...  0.023148  1.90960  1.368000   0.084467   \n",
       " 267  5.00040  3.5407   0.057492  ...  0.031155  0.96663  0.098211   0.016455   \n",
       " 409  2.50420  4.3347   0.094653  ...  0.085276  3.02100  0.082807   0.010623   \n",
       " \n",
       "      0.036038    0.0845   2.4517   3.3373  0.065201  0.091158  \n",
       " 135  0.159943  0.022060  1.20860  0.60768  0.009953  0.008511  \n",
       " 350  0.022934  0.072757  4.36710  3.44810  0.043674  0.088293  \n",
       " 512  0.074898  0.017203  0.30510  2.76760  0.017644  0.024415  \n",
       " 192  0.010765  0.030090  1.00030  4.19730  0.055218  0.000087  \n",
       " 27   0.087407  0.069206  4.73910  0.81070  0.044237  0.080280  \n",
       " ..        ...       ...      ...      ...       ...       ...  \n",
       " 570  0.081295  0.026455  4.65080  4.78760  0.025051  0.010176  \n",
       " 379  0.095847  0.085789  2.27940  2.34450  0.077262  0.021444  \n",
       " 162  0.070496  0.095554  3.67140  2.58712  0.502740  0.004556  \n",
       " 267  0.021214  0.050179  2.97540  2.98400  0.094157  0.001298  \n",
       " 409  0.002364  0.126290  0.82077  0.23743  0.050460  0.031783  \n",
       " \n",
       " [419 rows x 100 columns], 135    0\n",
       " 350    1\n",
       " 512    0\n",
       " 192    0\n",
       " 27     0\n",
       "       ..\n",
       " 570    1\n",
       " 379    0\n",
       " 162    1\n",
       " 267    0\n",
       " 409    0\n",
       " Name: label, Length: 419, dtype: int64, 'box-cox', False, True, None, 2401, [<pandas.io.formats.style.Styler at 0x7f62873eaee0>], {'lr': <pycaret.containers.models.classification.LogisticRegressionClassifierContainer at 0x7f62873b4bb0>,\n",
       "  'knn': <pycaret.containers.models.classification.KNeighborsClassifierContainer at 0x7f62873b48e0>,\n",
       "  'nb': <pycaret.containers.models.classification.GaussianNBClassifierContainer at 0x7f62873b4f40>,\n",
       "  'dt': <pycaret.containers.models.classification.DecisionTreeClassifierContainer at 0x7f62873b4dc0>,\n",
       "  'svm': <pycaret.containers.models.classification.SGDClassifierContainer at 0x7f62873b4fd0>,\n",
       "  'rbfsvm': <pycaret.containers.models.classification.SVCClassifierContainer at 0x7f62873b9f40>,\n",
       "  'gpc': <pycaret.containers.models.classification.GaussianProcessClassifierContainer at 0x7f62873b9c10>,\n",
       "  'mlp': <pycaret.containers.models.classification.MLPClassifierContainer at 0x7f62873b9280>,\n",
       "  'ridge': <pycaret.containers.models.classification.RidgeClassifierContainer at 0x7f62873b9490>,\n",
       "  'rf': <pycaret.containers.models.classification.RandomForestClassifierContainer at 0x7f62873b96a0>,\n",
       "  'qda': <pycaret.containers.models.classification.QuadraticDiscriminantAnalysisContainer at 0x7f62873b9e50>,\n",
       "  'ada': <pycaret.containers.models.classification.AdaBoostClassifierContainer at 0x7f62873c1130>,\n",
       "  'gbc': <pycaret.containers.models.classification.GradientBoostingClassifierContainer at 0x7f62873c1970>,\n",
       "  'lda': <pycaret.containers.models.classification.LinearDiscriminantAnalysisContainer at 0x7f62873c5910>,\n",
       "  'et': <pycaret.containers.models.classification.ExtraTreesClassifierContainer at 0x7f62873b4d90>,\n",
       "  'lightgbm': <pycaret.containers.models.classification.LGBMClassifierContainer at 0x7f62873c1280>,\n",
       "  'dummy': <pycaret.containers.models.classification.DummyClassifierContainer at 0x7f6284ad30a0>,\n",
       "  'Bagging': <pycaret.containers.models.classification.BaggingClassifierContainer at 0x7f62873b4fa0>,\n",
       "  'Stacking': <pycaret.containers.models.classification.StackingClassifierContainer at 0x7f6284ad32b0>,\n",
       "  'Voting': <pycaret.containers.models.classification.VotingClassifierContainer at 0x7f6284ad32e0>,\n",
       "  'CalibratedCV': <pycaret.containers.models.classification.CalibratedClassifierCVContainer at 0x7f6284ad3340>},      0.097094   1.1133      45.038  0.88184  0.087009    1.041   1.5486  \\\n",
       " 283  0.004545  4.51660   75.022003  2.76290  0.012198  2.31040  0.77615   \n",
       " 114  1.211200  2.06080  102.099998  4.04110  0.070464  3.31460  4.03200   \n",
       " 196  0.063410  1.17460  537.049988  2.45400  0.410730  1.24250  3.81970   \n",
       " 240  1.173600  0.91249  998.039978  4.86150  0.063294  4.93710  1.79430   \n",
       " 490  0.069527  4.63730   37.067001  2.88800  2.316500  3.04200  2.66620   \n",
       " ..        ...      ...         ...      ...       ...      ...      ...   \n",
       " 217  0.294420  4.86060  175.009995  1.88050  0.010787  0.68656  3.24140   \n",
       " 591  0.037083  0.99278   82.012001  0.50216  0.016304  2.92310  2.29020   \n",
       " 491  0.017581  0.21378  290.332397  5.04080  0.063831  4.48180  0.18684   \n",
       " 53   1.986700  4.01630  195.029999  2.11510  0.005662  0.17710  1.91220   \n",
       " 87   0.034872  3.92130    3.009700  4.48640  0.179734  3.64480  1.06840   \n",
       " \n",
       "        3.498   1.8578  0.0096729  ...  0.076209   3.6654  0.061607  0.0031605  \\\n",
       " 283  3.93900  1.60830   0.012352  ...  0.064753  1.83140  0.085747   0.003945   \n",
       " 114  3.43390  3.13390   0.091998  ...  0.092204  2.37330  0.603010   0.097772   \n",
       " 196  3.52040  0.58175   0.285350  ...  0.125480  0.29567  0.009743   0.063545   \n",
       " 240  0.73031  3.85860   0.018280  ...  0.075206  0.19932  0.440630   0.044663   \n",
       " 490  2.66810  4.51030   0.062818  ...  0.020653  3.36160  0.027805   0.046843   \n",
       " ..       ...      ...        ...  ...       ...      ...       ...        ...   \n",
       " 217  4.93670  2.41010   0.067848  ...  0.085276  4.63880  0.056897   0.029340   \n",
       " 591  2.26340  2.94420   0.002257  ...  0.001580  0.38663  0.051595   0.081419   \n",
       " 491  2.54255  4.62760   0.048206  ...  0.021260  1.08550  0.009202   0.026930   \n",
       " 53   1.37460  4.27320   0.018216  ...  0.042487  3.21830  0.090869   0.034099   \n",
       " 87   1.75100  3.40370   0.068675  ...  0.014249  4.06550  0.091715   0.038907   \n",
       " \n",
       "      0.036038    0.0845   2.4517   3.3373  0.065201  0.091158  \n",
       " 283  0.059616  0.087175  3.02530  0.23321  0.019455  0.064759  \n",
       " 114  0.159943  0.075531  3.62490  2.71540  0.077286  0.080498  \n",
       " 196  0.094313  0.038391  1.49720  0.55758  0.058696  0.067437  \n",
       " 240  0.099159  0.064509  0.46008  4.49620  0.183966  0.028864  \n",
       " 490  0.033029  0.046560  1.61980  3.77420  0.008120  0.099288  \n",
       " ..        ...       ...      ...      ...       ...       ...  \n",
       " 217  0.001489  0.253440  3.43630  3.58160  0.055288  0.258320  \n",
       " 591  0.095400  0.086999  3.91170  3.44170  0.055152  0.017789  \n",
       " 491  4.848400  0.010829  1.55480  2.60420  4.832600  0.165646  \n",
       " 53   0.010909  0.054046  2.70620  3.97480  0.026486  0.034971  \n",
       " 87   0.097601  0.016879  3.52390  4.17430  0.033931  0.025895  \n",
       " \n",
       " [180 rows x 100 columns], 'lightgbm', False, False, {'USI',\n",
       "  'X',\n",
       "  'X_test',\n",
       "  'X_train',\n",
       "  '_all_metrics',\n",
       "  '_all_models',\n",
       "  '_all_models_internal',\n",
       "  '_available_plots',\n",
       "  '_gpu_n_jobs_param',\n",
       "  '_internal_pipeline',\n",
       "  '_ml_usecase',\n",
       "  'create_model_container',\n",
       "  'dashboard_logger',\n",
       "  'data_before_preprocess',\n",
       "  'display_container',\n",
       "  'exp_name_log',\n",
       "  'experiment__',\n",
       "  'fix_imbalance_method_param',\n",
       "  'fix_imbalance_param',\n",
       "  'fold_generator',\n",
       "  'fold_groups_param',\n",
       "  'fold_groups_param_full',\n",
       "  'fold_param',\n",
       "  'fold_shuffle_param',\n",
       "  'gpu_param',\n",
       "  'html_param',\n",
       "  'imputation_classifier',\n",
       "  'imputation_regressor',\n",
       "  'iterative_imputation_iters_param',\n",
       "  'log_plots_param',\n",
       "  'logging_param',\n",
       "  'master_model_container',\n",
       "  'n_jobs_param',\n",
       "  'prep_pipe',\n",
       "  'pycaret_globals',\n",
       "  'seed',\n",
       "  'stratify_param',\n",
       "  'target_param',\n",
       "  'transform_target_method_param',\n",
       "  'transform_target_param',\n",
       "  'y',\n",
       "  'y_test',\n",
       "  'y_train'}, False, {'lr': <pycaret.containers.models.classification.LogisticRegressionClassifierContainer at 0x7f62873bc310>,\n",
       "  'knn': <pycaret.containers.models.classification.KNeighborsClassifierContainer at 0x7f62873bc4f0>,\n",
       "  'nb': <pycaret.containers.models.classification.GaussianNBClassifierContainer at 0x7f62873bca00>,\n",
       "  'dt': <pycaret.containers.models.classification.DecisionTreeClassifierContainer at 0x7f62873bce80>,\n",
       "  'svm': <pycaret.containers.models.classification.SGDClassifierContainer at 0x7f62873ae0d0>,\n",
       "  'rbfsvm': <pycaret.containers.models.classification.SVCClassifierContainer at 0x7f62873ea070>,\n",
       "  'gpc': <pycaret.containers.models.classification.GaussianProcessClassifierContainer at 0x7f628739ebe0>,\n",
       "  'mlp': <pycaret.containers.models.classification.MLPClassifierContainer at 0x7f628739ee50>,\n",
       "  'ridge': <pycaret.containers.models.classification.RidgeClassifierContainer at 0x7f62873feb20>,\n",
       "  'rf': <pycaret.containers.models.classification.RandomForestClassifierContainer at 0x7f62873feeb0>,\n",
       "  'qda': <pycaret.containers.models.classification.QuadraticDiscriminantAnalysisContainer at 0x7f62873fe7c0>,\n",
       "  'ada': <pycaret.containers.models.classification.AdaBoostClassifierContainer at 0x7f6290a52cd0>,\n",
       "  'gbc': <pycaret.containers.models.classification.GradientBoostingClassifierContainer at 0x7f62873c5310>,\n",
       "  'lda': <pycaret.containers.models.classification.LinearDiscriminantAnalysisContainer at 0x7f62873c5640>,\n",
       "  'et': <pycaret.containers.models.classification.ExtraTreesClassifierContainer at 0x7f62873c5280>,\n",
       "  'lightgbm': <pycaret.containers.models.classification.LGBMClassifierContainer at 0x7f62873b4460>,\n",
       "  'dummy': <pycaret.containers.models.classification.DummyClassifierContainer at 0x7f62873b4d30>}, False, 'befe', 283    1\n",
       " 114    1\n",
       " 196    0\n",
       " 240    1\n",
       " 490    0\n",
       "       ..\n",
       " 217    1\n",
       " 591    0\n",
       " 491    0\n",
       " 53     0\n",
       " 87     0\n",
       " Name: label, Length: 180, dtype: int64, 'label', 0      1\n",
       " 1      0\n",
       " 2      0\n",
       " 3      1\n",
       " 4      0\n",
       "       ..\n",
       " 594    1\n",
       " 595    0\n",
       " 596    1\n",
       " 597    0\n",
       " 598    0\n",
       " Name: label, Length: 599, dtype: int64, Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=[],\n",
       "                                       display_types=True, features_todrop=[],\n",
       "                                       id_columns=[],\n",
       "                                       ml_usecase='classification',\n",
       "                                       numerical_features=[], target='label',\n",
       "                                       time_features=[])),\n",
       "                 ('imputer',\n",
       "                  Simple_Imputer(categorical_strategy='not_available',\n",
       "                                 fill_value_categorical=None,\n",
       "                                 fill_value_numerical=None,\n",
       "                                 numeric_strate...\n",
       "                 ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
       "                 ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
       "                 ('cluster_all', 'passthrough'),\n",
       "                 ('dummy', Dummify(target='label')),\n",
       "                 ('fix_perfect', Remove_100(target='label')),\n",
       "                 ('clean_names', Clean_Colum_Names()),\n",
       "                 ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
       "                 ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
       "          verbose=False), 'clf-default-name',      0.097094   1.1133     45.038  0.88184  0.087009    1.041    1.5486  \\\n",
       " 0    0.050086  0.11158    94.0800  1.76500  0.089417  4.80470  0.267420   \n",
       " 1    0.088447  2.36340     5.0580  0.14436  0.064547  2.44400  4.254500   \n",
       " 2    0.772540  0.59469        NaN  0.97515  0.015987  0.52884  1.488400   \n",
       " 3    0.382410  4.81090  1955.1000  0.46050  0.024453  2.02980  3.740300   \n",
       " 4    0.081316  4.84150     4.0507  2.48320  0.058990  2.37940  1.612700   \n",
       " ..        ...      ...        ...      ...       ...      ...       ...   \n",
       " 594  0.083012  4.44000  1140.1000  5.04650  0.069693  4.32170  2.652700   \n",
       " 595  0.523780  3.32790   122.0500  3.54630  1.010900  1.72230  3.131200   \n",
       " 596  0.995510  1.60620   464.0900  3.58910  0.091039  1.62010  3.688400   \n",
       " 597  1.208000  2.10000    24.0110  2.92140  0.055663  0.78477  1.288900   \n",
       " 598  0.083476  2.86980    37.0740  3.08970  0.086909  4.91600  0.087911   \n",
       " \n",
       "        3.498   1.8578  0.0096729  ...   3.6654  0.061607  0.0031605  0.036038  \\\n",
       " 0        NaN  0.56473   0.035123  ...  4.16870  0.075432   0.010869  0.063972   \n",
       " 1    0.36506  1.86090   0.009759  ...  4.56130  0.046505        NaN  0.084066   \n",
       " 2    3.96100  4.80630   0.048617  ...  0.12832  0.065028   0.036862  0.010010   \n",
       " 3    4.22810  2.42920   0.156830  ...  4.37010  1.001100   0.065750  0.043547   \n",
       " 4    2.04220  1.65710   0.039377  ...  2.68040  0.076524   0.082756  0.041953   \n",
       " ..       ...      ...        ...  ...      ...       ...        ...       ...   \n",
       " 594  4.80340  4.91870   0.088879  ...  3.50690  0.518980   0.047767  0.061994   \n",
       " 595  3.75900  3.61270   0.061250  ...  1.55980  0.023365   1.084000  0.072553   \n",
       " 596  1.84550  0.41606   0.548030  ...  3.32090  0.019906   0.057709  0.097567   \n",
       " 597  3.18080  4.77850   0.050453  ...  2.48810  0.061171   0.070312       NaN   \n",
       " 598  2.55460  2.13250   0.069508  ...  0.12656  0.085419   0.002887  0.007303   \n",
       " \n",
       "        0.0845   2.4517  3.3373  0.065201  0.091158  label  \n",
       " 0    0.079892  1.97950  3.5064  0.072132  0.091950      1  \n",
       " 1    0.064829  3.30870  2.9969  0.064328  0.036793      0  \n",
       " 2    0.020709  2.52370  2.1711  0.080865  0.081553      0  \n",
       " 3    0.629430  4.62620  3.1947       NaN  0.187180      1  \n",
       " 4    0.018092  3.30410  0.1922  0.032600  0.050172      0  \n",
       " ..        ...      ...     ...       ...       ...    ...  \n",
       " 594  0.256460  3.57210  4.7692  0.056299  0.162660      1  \n",
       " 595  0.049359  3.46930  3.1465  0.031458  0.019107      0  \n",
       " 596  0.073208  0.62583  4.6044  0.071155  0.053476      1  \n",
       " 597  0.043862  0.58203  4.5994  0.045182  0.031991      0  \n",
       " 598  0.009501  4.80320  1.7190  0.054735  0.035035      0  \n",
       " \n",
       " [599 rows x 101 columns], <MLUsecase.CLASSIFICATION: 1>,      0.097094   1.1133       45.038  0.88184  0.087009    1.041    1.5486  \\\n",
       " 0    0.050086  0.11158    94.080002  1.76500  0.089417  4.80470  0.267420   \n",
       " 1    0.088447  2.36340     5.058000  0.14436  0.064547  2.44400  4.254500   \n",
       " 2    0.772540  0.59469   290.332397  0.97515  0.015987  0.52884  1.488400   \n",
       " 3    0.382410  4.81090  1955.099976  0.46050  0.024453  2.02980  3.740300   \n",
       " 4    0.081316  4.84150     4.050700  2.48320  0.058990  2.37940  1.612700   \n",
       " ..        ...      ...          ...      ...       ...      ...       ...   \n",
       " 594  0.083012  4.44000  1140.099976  5.04650  0.069693  4.32170  2.652700   \n",
       " 595  0.523780  3.32790   122.050003  3.54630  1.010900  1.72230  3.131200   \n",
       " 596  0.995510  1.60620   464.089996  3.58910  0.091039  1.62010  3.688400   \n",
       " 597  1.208000  2.10000    24.011000  2.92140  0.055663  0.78477  1.288900   \n",
       " 598  0.083476  2.86980    37.074001  3.08970  0.086909  4.91600  0.087911   \n",
       " \n",
       "        3.498   1.8578  0.0096729  ...  0.076209   3.6654  0.061607  0.0031605  \\\n",
       " 0    2.54255  0.56473   0.035123  ...  0.054712  4.16870  0.075432   0.010869   \n",
       " 1    0.36506  1.86090   0.009759  ...  0.017203  4.56130  0.046505   0.103860   \n",
       " 2    3.96100  4.80630   0.048617  ...  0.022891  0.12832  0.065028   0.036862   \n",
       " 3    4.22810  2.42920   0.156830  ...  0.032051  4.37010  1.001100   0.065750   \n",
       " 4    2.04220  1.65710   0.039377  ...  0.018918  2.68040  0.076524   0.082756   \n",
       " ..       ...      ...        ...  ...       ...      ...       ...        ...   \n",
       " 594  4.80340  4.91870   0.088879  ...  0.054703  3.50690  0.518980   0.047767   \n",
       " 595  3.75900  3.61270   0.061250  ...  0.351960  1.55980  0.023365   1.084000   \n",
       " 596  1.84550  0.41606   0.548030  ...  0.114580  3.32090  0.019906   0.057709   \n",
       " 597  3.18080  4.77850   0.050453  ...  0.011022  2.48810  0.061171   0.070312   \n",
       " 598  2.55460  2.13250   0.069508  ...  0.615660  0.12656  0.085419   0.002887   \n",
       " \n",
       "      0.036038    0.0845   2.4517  3.3373  0.065201  0.091158  \n",
       " 0    0.063972  0.079892  1.97950  3.5064  0.072132  0.091950  \n",
       " 1    0.084066  0.064829  3.30870  2.9969  0.064328  0.036793  \n",
       " 2    0.010010  0.020709  2.52370  2.1711  0.080865  0.081553  \n",
       " 3    0.043547  0.629430  4.62620  3.1947  0.183966  0.187180  \n",
       " 4    0.041953  0.018092  3.30410  0.1922  0.032600  0.050172  \n",
       " ..        ...       ...      ...     ...       ...       ...  \n",
       " 594  0.061994  0.256460  3.57210  4.7692  0.056299  0.162660  \n",
       " 595  0.072553  0.049359  3.46930  3.1465  0.031458  0.019107  \n",
       " 596  0.097567  0.073208  0.62583  4.6044  0.071155  0.053476  \n",
       " 597  0.159943  0.043862  0.58203  4.5994  0.045182  0.031991  \n",
       " 598  0.007303  0.009501  4.80320  1.7190  0.054735  0.035035  \n",
       " \n",
       " [599 rows x 100 columns], {'parameter': 'Hyperparameters',\n",
       "  'auc': 'AUC',\n",
       "  'confusion_matrix': 'Confusion Matrix',\n",
       "  'threshold': 'Threshold',\n",
       "  'pr': 'Precision Recall',\n",
       "  'error': 'Prediction Error',\n",
       "  'class_report': 'Class Report',\n",
       "  'rfe': 'Feature Selection',\n",
       "  'learning': 'Learning Curve',\n",
       "  'manifold': 'Manifold Learning',\n",
       "  'calibration': 'Calibration Curve',\n",
       "  'vc': 'Validation Curve',\n",
       "  'dimension': 'Dimensions',\n",
       "  'feature': 'Feature Importance',\n",
       "  'feature_all': 'Feature Importance (All)',\n",
       "  'boundary': 'Decision Boundary',\n",
       "  'lift': 'Lift Chart',\n",
       "  'gain': 'Gain Chart',\n",
       "  'tree': 'Decision Tree',\n",
       "  'ks': 'KS Statistic Plot'}, 10, -1, None, None, 5, {'acc': <pycaret.containers.metrics.classification.AccuracyMetricContainer at 0x7f6284ad33a0>,\n",
       "  'auc': <pycaret.containers.metrics.classification.ROCAUCMetricContainer at 0x7f6284ad33d0>,\n",
       "  'recall': <pycaret.containers.metrics.classification.RecallMetricContainer at 0x7f6284ad3460>,\n",
       "  'precision': <pycaret.containers.metrics.classification.PrecisionMetricContainer at 0x7f6284ad35b0>,\n",
       "  'f1': <pycaret.containers.metrics.classification.F1MetricContainer at 0x7f6284ad3700>,\n",
       "  'kappa': <pycaret.containers.metrics.classification.KappaMetricContainer at 0x7f6284ad3850>,\n",
       "  'mcc': <pycaret.containers.metrics.classification.MCCMetricContainer at 0x7f6284ad38e0>}, 'lightgbm', [('Setup Config',\n",
       "                                  Description             Value\n",
       "   0                               session_id              2401\n",
       "   1                                   Target             label\n",
       "   2                              Target Type            Binary\n",
       "   3                            Label Encoded              None\n",
       "   4                            Original Data        (599, 101)\n",
       "   5                           Missing Values              True\n",
       "   6                         Numeric Features               100\n",
       "   7                     Categorical Features                 0\n",
       "   8                         Ordinal Features             False\n",
       "   9                High Cardinality Features             False\n",
       "   10                 High Cardinality Method              None\n",
       "   11                   Transformed Train Set        (419, 100)\n",
       "   12                    Transformed Test Set        (180, 100)\n",
       "   13                      Shuffle Train-Test              True\n",
       "   14                     Stratify Train-Test             False\n",
       "   15                          Fold Generator   StratifiedKFold\n",
       "   16                             Fold Number                10\n",
       "   17                                CPU Jobs                -1\n",
       "   18                                 Use GPU             False\n",
       "   19                          Log Experiment             False\n",
       "   20                         Experiment Name  clf-default-name\n",
       "   21                                     USI              befe\n",
       "   22                         Imputation Type            simple\n",
       "   23          Iterative Imputation Iteration              None\n",
       "   24                         Numeric Imputer              mean\n",
       "   25      Iterative Imputation Numeric Model              None\n",
       "   26                     Categorical Imputer          constant\n",
       "   27  Iterative Imputation Categorical Model              None\n",
       "   28           Unknown Categoricals Handling    least_frequent\n",
       "   29                               Normalize             False\n",
       "   30                        Normalize Method              None\n",
       "   31                          Transformation             False\n",
       "   32                   Transformation Method              None\n",
       "   33                                     PCA             False\n",
       "   34                              PCA Method              None\n",
       "   35                          PCA Components              None\n",
       "   36                     Ignore Low Variance             False\n",
       "   37                     Combine Rare Levels             False\n",
       "   38                    Rare Level Threshold              None\n",
       "   39                         Numeric Binning             False\n",
       "   40                         Remove Outliers             False\n",
       "   41                      Outliers Threshold              None\n",
       "   42                Remove Multicollinearity             False\n",
       "   43             Multicollinearity Threshold              None\n",
       "   44             Remove Perfect Collinearity              True\n",
       "   45                              Clustering             False\n",
       "   46                    Clustering Iteration              None\n",
       "   47                     Polynomial Features             False\n",
       "   48                       Polynomial Degree              None\n",
       "   49                    Trignometry Features             False\n",
       "   50                    Polynomial Threshold              None\n",
       "   51                          Group Features             False\n",
       "   52                       Feature Selection             False\n",
       "   53                Feature Selection Method           classic\n",
       "   54            Features Selection Threshold              None\n",
       "   55                     Feature Interaction             False\n",
       "   56                           Feature Ratio             False\n",
       "   57                   Interaction Threshold              None\n",
       "   58                           Fix Imbalance             False\n",
       "   59                    Fix Imbalance Method             SMOTE),\n",
       "  ('X_training Set',\n",
       "        0.097094   1.1133       45.038  0.88184  0.087009    1.041   1.5486  \\\n",
       "   135  0.074281  4.47860     9.099700  0.15208  0.179734  2.55650  2.06890   \n",
       "   350  0.002583  4.13580    51.084999  0.30122  0.081628  2.21820  0.84725   \n",
       "   512  0.067082  4.46350   290.332397  1.23530  0.089795  4.77930  3.38170   \n",
       "   192  0.809040  4.94900    71.044998  1.54530  0.765080  1.02950  3.90200   \n",
       "   27   0.040834  4.39190    19.082001  3.90900  0.031405  1.17960  3.68010   \n",
       "   ..        ...      ...          ...      ...       ...      ...      ...   \n",
       "   570  0.066086  3.15590   826.020020  1.21120  0.050190  1.08990  4.61700   \n",
       "   379  0.058969  2.28610    79.084000  3.33980  0.010935  3.39960  1.85280   \n",
       "   162  0.017473  4.53250    65.065002  3.34090  0.020600  4.32710  2.53770   \n",
       "   267  0.044203  0.60286    99.008003  1.75950  0.050305  1.58640  4.76790   \n",
       "   409  0.045725  1.15330  1463.099976  0.99884  0.059217  0.49536  3.33280   \n",
       "   \n",
       "          3.498  1.8578  0.0096729  ...  0.076209   3.6654  0.061607  0.0031605  \\\n",
       "   135  4.33640  1.3526   0.095312  ...  0.014924  2.72280  0.083425   0.071522   \n",
       "   350  3.16850  3.1680   0.005478  ...  0.052129  0.34151  0.003804   0.067689   \n",
       "   512  3.84310  2.2026   0.028238  ...  0.032006  2.33270  0.075470   0.020081   \n",
       "   192  0.92241  2.7170   0.073644  ...  0.005704  2.20000  0.077198   0.048482   \n",
       "   27   4.27760  1.0407   0.087270  ...  0.057945  0.64577  0.009417   0.053599   \n",
       "   ..       ...     ...        ...  ...       ...      ...       ...        ...   \n",
       "   570  2.65490  2.1883   0.046694  ...  0.050400  2.57820  0.045104   0.039356   \n",
       "   379  4.86760  2.2228   0.087276  ...  0.033458  1.31050  0.021490   0.009631   \n",
       "   162  2.41710  4.6191   0.006833  ...  0.023148  1.90960  1.368000   0.084467   \n",
       "   267  5.00040  3.5407   0.057492  ...  0.031155  0.96663  0.098211   0.016455   \n",
       "   409  2.50420  4.3347   0.094653  ...  0.085276  3.02100  0.082807   0.010623   \n",
       "   \n",
       "        0.036038    0.0845   2.4517   3.3373  0.065201  0.091158  \n",
       "   135  0.159943  0.022060  1.20860  0.60768  0.009953  0.008511  \n",
       "   350  0.022934  0.072757  4.36710  3.44810  0.043674  0.088293  \n",
       "   512  0.074898  0.017203  0.30510  2.76760  0.017644  0.024415  \n",
       "   192  0.010765  0.030090  1.00030  4.19730  0.055218  0.000087  \n",
       "   27   0.087407  0.069206  4.73910  0.81070  0.044237  0.080280  \n",
       "   ..        ...       ...      ...      ...       ...       ...  \n",
       "   570  0.081295  0.026455  4.65080  4.78760  0.025051  0.010176  \n",
       "   379  0.095847  0.085789  2.27940  2.34450  0.077262  0.021444  \n",
       "   162  0.070496  0.095554  3.67140  2.58712  0.502740  0.004556  \n",
       "   267  0.021214  0.050179  2.97540  2.98400  0.094157  0.001298  \n",
       "   409  0.002364  0.126290  0.82077  0.23743  0.050460  0.031783  \n",
       "   \n",
       "   [419 rows x 100 columns]),\n",
       "  ('y_training Set', 135    0\n",
       "   350    1\n",
       "   512    0\n",
       "   192    0\n",
       "   27     0\n",
       "         ..\n",
       "   570    1\n",
       "   379    0\n",
       "   162    1\n",
       "   267    0\n",
       "   409    0\n",
       "   Name: label, Length: 419, dtype: int64),\n",
       "  ('X_test Set',\n",
       "        0.097094   1.1133      45.038  0.88184  0.087009    1.041   1.5486  \\\n",
       "   283  0.004545  4.51660   75.022003  2.76290  0.012198  2.31040  0.77615   \n",
       "   114  1.211200  2.06080  102.099998  4.04110  0.070464  3.31460  4.03200   \n",
       "   196  0.063410  1.17460  537.049988  2.45400  0.410730  1.24250  3.81970   \n",
       "   240  1.173600  0.91249  998.039978  4.86150  0.063294  4.93710  1.79430   \n",
       "   490  0.069527  4.63730   37.067001  2.88800  2.316500  3.04200  2.66620   \n",
       "   ..        ...      ...         ...      ...       ...      ...      ...   \n",
       "   217  0.294420  4.86060  175.009995  1.88050  0.010787  0.68656  3.24140   \n",
       "   591  0.037083  0.99278   82.012001  0.50216  0.016304  2.92310  2.29020   \n",
       "   491  0.017581  0.21378  290.332397  5.04080  0.063831  4.48180  0.18684   \n",
       "   53   1.986700  4.01630  195.029999  2.11510  0.005662  0.17710  1.91220   \n",
       "   87   0.034872  3.92130    3.009700  4.48640  0.179734  3.64480  1.06840   \n",
       "   \n",
       "          3.498   1.8578  0.0096729  ...  0.076209   3.6654  0.061607  0.0031605  \\\n",
       "   283  3.93900  1.60830   0.012352  ...  0.064753  1.83140  0.085747   0.003945   \n",
       "   114  3.43390  3.13390   0.091998  ...  0.092204  2.37330  0.603010   0.097772   \n",
       "   196  3.52040  0.58175   0.285350  ...  0.125480  0.29567  0.009743   0.063545   \n",
       "   240  0.73031  3.85860   0.018280  ...  0.075206  0.19932  0.440630   0.044663   \n",
       "   490  2.66810  4.51030   0.062818  ...  0.020653  3.36160  0.027805   0.046843   \n",
       "   ..       ...      ...        ...  ...       ...      ...       ...        ...   \n",
       "   217  4.93670  2.41010   0.067848  ...  0.085276  4.63880  0.056897   0.029340   \n",
       "   591  2.26340  2.94420   0.002257  ...  0.001580  0.38663  0.051595   0.081419   \n",
       "   491  2.54255  4.62760   0.048206  ...  0.021260  1.08550  0.009202   0.026930   \n",
       "   53   1.37460  4.27320   0.018216  ...  0.042487  3.21830  0.090869   0.034099   \n",
       "   87   1.75100  3.40370   0.068675  ...  0.014249  4.06550  0.091715   0.038907   \n",
       "   \n",
       "        0.036038    0.0845   2.4517   3.3373  0.065201  0.091158  \n",
       "   283  0.059616  0.087175  3.02530  0.23321  0.019455  0.064759  \n",
       "   114  0.159943  0.075531  3.62490  2.71540  0.077286  0.080498  \n",
       "   196  0.094313  0.038391  1.49720  0.55758  0.058696  0.067437  \n",
       "   240  0.099159  0.064509  0.46008  4.49620  0.183966  0.028864  \n",
       "   490  0.033029  0.046560  1.61980  3.77420  0.008120  0.099288  \n",
       "   ..        ...       ...      ...      ...       ...       ...  \n",
       "   217  0.001489  0.253440  3.43630  3.58160  0.055288  0.258320  \n",
       "   591  0.095400  0.086999  3.91170  3.44170  0.055152  0.017789  \n",
       "   491  4.848400  0.010829  1.55480  2.60420  4.832600  0.165646  \n",
       "   53   0.010909  0.054046  2.70620  3.97480  0.026486  0.034971  \n",
       "   87   0.097601  0.016879  3.52390  4.17430  0.033931  0.025895  \n",
       "   \n",
       "   [180 rows x 100 columns]),\n",
       "  ('y_test Set', 283    1\n",
       "   114    1\n",
       "   196    0\n",
       "   240    1\n",
       "   490    0\n",
       "         ..\n",
       "   217    1\n",
       "   591    0\n",
       "   491    0\n",
       "   53     0\n",
       "   87     0\n",
       "   Name: label, Length: 180, dtype: int64),\n",
       "  ('Transformation Pipeline', Pipeline(memory=None,\n",
       "            steps=[('dtypes',\n",
       "                    DataTypes_Auto_infer(categorical_features=[],\n",
       "                                         display_types=True, features_todrop=[],\n",
       "                                         id_columns=[],\n",
       "                                         ml_usecase='classification',\n",
       "                                         numerical_features=[], target='label',\n",
       "                                         time_features=[])),\n",
       "                   ('imputer',\n",
       "                    Simple_Imputer(categorical_strategy='not_available',\n",
       "                                   fill_value_categorical=None,\n",
       "                                   fill_value_numerical=None,\n",
       "                                   numeric_strate...\n",
       "                   ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
       "                   ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
       "                   ('cluster_all', 'passthrough'),\n",
       "                   ('dummy', Dummify(target='label')),\n",
       "                   ('fix_perfect', Remove_100(target='label')),\n",
       "                   ('clean_names', Clean_Colum_Names()),\n",
       "                   ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
       "                   ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
       "            verbose=False))], -1, [], [], False, None, StratifiedKFold(n_splits=10, random_state=None, shuffle=False), False, Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup(df, target=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 775,
     "referenced_widgets": [
      "a4c1aa90908948978673406b55557732",
      "ade769c34f5f4679b1558240362f67d7",
      "ec2815d8b63b4b96bc0abab51af42346"
     ]
    },
    "id": "j5sMkyIv4zxB",
    "outputId": "0d47c152-ed8b-4fb7-86d8-069d439e2070"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3747982e-5679-4f24-8d52-eb2c033f154c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>0.9211</td>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.8686</td>\n",
       "      <td>0.9399</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.8394</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.8804</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>0.8972</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.8331</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.8399</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.8196</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.8973</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>0.8972</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>0.7873</td>\n",
       "      <td>0.7914</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.9122</td>\n",
       "      <td>0.8655</td>\n",
       "      <td>0.7798</td>\n",
       "      <td>0.7846</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.8685</td>\n",
       "      <td>0.9265</td>\n",
       "      <td>0.7938</td>\n",
       "      <td>0.8838</td>\n",
       "      <td>0.8314</td>\n",
       "      <td>0.7249</td>\n",
       "      <td>0.7325</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8495</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.8279</td>\n",
       "      <td>0.8194</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.6983</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.7967</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.9122</td>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.7971</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>0.6365</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.7993</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>0.9542</td>\n",
       "      <td>0.6913</td>\n",
       "      <td>0.7997</td>\n",
       "      <td>0.6098</td>\n",
       "      <td>0.6458</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>0.6920</td>\n",
       "      <td>0.7367</td>\n",
       "      <td>0.5882</td>\n",
       "      <td>0.6484</td>\n",
       "      <td>0.6139</td>\n",
       "      <td>0.3588</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "      <td>0.6633</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.6484</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.2930</td>\n",
       "      <td>0.3218</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>0.5823</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3747982e-5679-4f24-8d52-eb2c033f154c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3747982e-5679-4f24-8d52-eb2c033f154c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3747982e-5679-4f24-8d52-eb2c033f154c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
       "lightgbm  Light Gradient Boosting Machine    0.9211  0.9624  0.8686  0.9399   \n",
       "gbc          Gradient Boosting Classifier    0.9164  0.9683  0.8804  0.9237   \n",
       "rf               Random Forest Classifier    0.9139  0.9633  0.8399  0.9506   \n",
       "ada                  Ada Boost Classifier    0.8973  0.9520  0.8569  0.8972   \n",
       "et                 Extra Trees Classifier    0.8948  0.9583  0.8278  0.9122   \n",
       "qda       Quadratic Discriminant Analysis    0.8685  0.9265  0.7938  0.8838   \n",
       "lr                    Logistic Regression    0.8495  0.9327  0.8225  0.8279   \n",
       "ridge                    Ridge Classifier    0.8448  0.0000  0.7428  0.8725   \n",
       "lda          Linear Discriminant Analysis    0.8448  0.9122  0.7422  0.8768   \n",
       "dt               Decision Tree Classifier    0.8211  0.8154  0.7778  0.7975   \n",
       "nb                            Naive Bayes    0.7993  0.9321  0.9542  0.6913   \n",
       "knn                K Neighbors Classifier    0.6920  0.7367  0.5882  0.6484   \n",
       "svm                   SVM - Linear Kernel    0.6633  0.0000  0.5275  0.6484   \n",
       "dummy                    Dummy Classifier    0.5823  0.5000  0.0000  0.0000   \n",
       "\n",
       "              F1   Kappa     MCC  TT (Sec)  \n",
       "lightgbm  0.9014  0.8360  0.8394     0.314  \n",
       "gbc       0.8972  0.8272  0.8331     0.902  \n",
       "rf        0.8892  0.8196  0.8261     0.475  \n",
       "ada       0.8735  0.7873  0.7914     0.425  \n",
       "et        0.8655  0.7798  0.7846     0.211  \n",
       "qda       0.8314  0.7249  0.7325     0.022  \n",
       "lr        0.8194  0.6909  0.6983     0.766  \n",
       "ridge     0.7967  0.6735  0.6840     0.017  \n",
       "lda       0.7971  0.6735  0.6855     0.026  \n",
       "dt        0.7833  0.6316  0.6365     0.034  \n",
       "nb        0.7997  0.6098  0.6458     0.015  \n",
       "knn       0.6139  0.3588  0.3624     0.026  \n",
       "svm       0.5435  0.2930  0.3218     0.016  \n",
       "dummy     0.0000  0.0000  0.0000     0.016  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logs:create_model_container: 14\n",
      "INFO:logs:master_model_container: 14\n",
      "INFO:logs:display_container: 2\n",
      "INFO:logs:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "               random_state=2401, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
      "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
      "INFO:logs:compare_models() succesfully completed......................................\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=2401, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypovotQt4-u9"
   },
   "source": [
    "In this model using PyCaret, the best result shows Light Grading Boosting Machine with an accuracy of 92,11%, which is slightly less than the model we build on kaggle with an acc of 96% with the XBGClassifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 636,
     "referenced_widgets": [
      "ce2fa2055d404c0b904fe8244054f59e",
      "9f13530362d64d5593777f39a0ab00cd",
      "49ea1c9b0d404cbcb0cad706f578cc5d"
     ]
    },
    "id": "xo64dT5z5AJJ",
    "outputId": "41f62059-ba12-4608-8aed-6141e3a754b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7e4a590e-587a-4a8d-a8f8-a71463d3f198\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.8012</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.5753</td>\n",
       "      <td>0.5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.8318</td>\n",
       "      <td>0.8235</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.6573</td>\n",
       "      <td>0.6581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>0.8235</td>\n",
       "      <td>0.8235</td>\n",
       "      <td>0.8235</td>\n",
       "      <td>0.7035</td>\n",
       "      <td>0.7035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.8024</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.6047</td>\n",
       "      <td>0.6047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.7429</td>\n",
       "      <td>0.5594</td>\n",
       "      <td>0.5601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.7895</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>0.6628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.7895</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>0.6628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.8472</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8235</td>\n",
       "      <td>0.7042</td>\n",
       "      <td>0.7077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.7431</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8537</td>\n",
       "      <td>0.8321</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.6878</td>\n",
       "      <td>0.7032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>0.6365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std</th>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>0.0637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e4a590e-587a-4a8d-a8f8-a71463d3f198')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7e4a590e-587a-4a8d-a8f8-a71463d3f198 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7e4a590e-587a-4a8d-a8f8-a71463d3f198');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "Fold                                                          \n",
       "0       0.7857  0.8012  0.8824  0.6818  0.7692  0.5753  0.5920\n",
       "1       0.8333  0.8318  0.8235  0.7778  0.8000  0.6573  0.6581\n",
       "2       0.8571  0.8518  0.8235  0.8235  0.8235  0.7035  0.7035\n",
       "3       0.8095  0.8024  0.7647  0.7647  0.7647  0.6047  0.6047\n",
       "4       0.7857  0.7778  0.7222  0.7647  0.7429  0.5594  0.5601\n",
       "5       0.8333  0.8333  0.8333  0.7895  0.8108  0.6621  0.6628\n",
       "6       0.8333  0.8333  0.8333  0.7895  0.8108  0.6621  0.6628\n",
       "7       0.8571  0.8472  0.7778  0.8750  0.8235  0.7042  0.7077\n",
       "8       0.7619  0.7431  0.6111  0.7857  0.6875  0.5000  0.5103\n",
       "9       0.8537  0.8321  0.7059  0.9231  0.8000  0.6878  0.7032\n",
       "Mean    0.8211  0.8154  0.7778  0.7975  0.7833  0.6316  0.6365\n",
       "Std     0.0320  0.0325  0.0758  0.0622  0.0408  0.0652  0.0637"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logs:create_model_container: 15\n",
      "INFO:logs:master_model_container: 15\n",
      "INFO:logs:display_container: 3\n",
      "INFO:logs:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=2401, splitter='best')\n",
      "INFO:logs:create_model() succesfully completed......................................\n"
     ]
    }
   ],
   "source": [
    "dt=create_model('dt',fold=10) # runs the data 10 times and shows best results (K-Folds Cross-Validation)\n",
    "# divides the data part by part while training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIDR-rpN5gG0"
   },
   "source": [
    "Mean Accuracy is at 82,11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63xjQ3JV47To"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "074394ebaeec48c7a79e22e9ff612494": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49ea1c9b0d404cbcb0cad706f578cc5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "56a54250ee2b45468c1e479d3af220aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "59b3b564ff124922bb9dc39c5bb4b33a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "6226060639964853b57c6d65dc8882c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_59b3b564ff124922bb9dc39c5bb4b33a",
      "placeholder": "",
      "style": "IPY_MODEL_074394ebaeec48c7a79e22e9ff612494",
      "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise."
     }
    },
    "9f13530362d64d5593777f39a0ab00cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4c1aa90908948978673406b55557732": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ade769c34f5f4679b1558240362f67d7",
      "max": 74,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec2815d8b63b4b96bc0abab51af42346",
      "value": 74
     }
    },
    "aac1e7363822434c8c8330d6689f9324": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ade769c34f5f4679b1558240362f67d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce2fa2055d404c0b904fe8244054f59e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f13530362d64d5593777f39a0ab00cd",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49ea1c9b0d404cbcb0cad706f578cc5d",
      "value": 4
     }
    },
    "ec2815d8b63b4b96bc0abab51af42346": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fb41d15456094cf8b086eac8938af7d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aac1e7363822434c8c8330d6689f9324",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_56a54250ee2b45468c1e479d3af220aa",
      "value": 3
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
